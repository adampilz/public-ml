{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61935cab-b5d2-4a64-a7dc-c19df48d6407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this the first time you use the notebook\n",
    "! pip install -U google-cloud-vision\n",
    "# must restart kernel after running this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e7211-0164-4cb8-ba9c-1d14d323bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google\n",
    "from google.cloud import storage\n",
    "\n",
    "# cloud vision api\n",
    "from google.cloud import vision\n",
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf5af6c-bbbc-4105-84e3-adaf0757bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print(\"Texts:\")\n",
    "\n",
    "    for text in texts:\n",
    "        print(f'\\n\"{text.description}\"')\n",
    "\n",
    "        vertices = [\n",
    "            f\"({vertex.x},{vertex.y})\" for vertex in text.bounding_poly.vertices\n",
    "        ]\n",
    "\n",
    "        print(\"bounds: {}\".format(\",\".join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "def localize_objects(path):\n",
    "    \"\"\"Localize objects in the local image.\n",
    "\n",
    "    Args:\n",
    "    path: The path to the local file.\n",
    "    \"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    objects = client.object_localization(image=image).localized_object_annotations\n",
    "\n",
    "    print(f\"Number of objects found: {len(objects)}\")\n",
    "    for object_ in objects:\n",
    "        print(f\"\\n{object_.name} (confidence: {object_.score})\")\n",
    "        print(\"Normalized bounding polygon vertices: \")\n",
    "        for vertex in object_.bounding_poly.normalized_vertices:\n",
    "            print(f\" - ({vertex.x}, {vertex.y})\")\n",
    "            \n",
    "def detect_labels(path):\n",
    "    \"\"\"Detects labels in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    print(\"Labels:\")\n",
    "\n",
    "    for label in labels:\n",
    "        print(label.description)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "        \n",
    "def detect_properties(path):\n",
    "    \"\"\"Detects image properties in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.image_properties(image=image)\n",
    "    props = response.image_properties_annotation\n",
    "    print(\"Properties:\")\n",
    "\n",
    "    for color in props.dominant_colors.colors:\n",
    "        print(f\"fraction: {color.pixel_fraction}\")\n",
    "        print(f\"\\tr: {color.color.red}\")\n",
    "        print(f\"\\tg: {color.color.green}\")\n",
    "        print(f\"\\tb: {color.color.blue}\")\n",
    "        print(f\"\\ta: {color.color.alpha}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd0760-1931-4e09-8acf-16898595a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an image\n",
    "img = \"wildcats_hat_1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f868362b-fc9d-4653-b39c-162e7aac8601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects found: 1\n",
      "\n",
      "Top (confidence: 0.8842754364013672)\n",
      "Normalized bounding polygon vertices: \n",
      " - (0.1904907077550888, 0.005753574892878532)\n",
      " - (0.7754279971122742, 0.005753574892878532)\n",
      " - (0.7754279971122742, 0.9973958134651184)\n",
      " - (0.1904907077550888, 0.9973958134651184)\n"
     ]
    }
   ],
   "source": [
    "localize_objects(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "832f3149-4395-4cff-9149-231350b24e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts:\n",
      "\n",
      "\"PRIMEBLUE\n",
      "1\"\n",
      "bounds: (208,24),(950,24),(950,1310),(208,1310)\n",
      "\n",
      "\"PRIMEBLUE\"\n",
      "bounds: (449,24),(524,25),(524,37),(449,36)\n",
      "\n",
      "\"1\"\n",
      "bounds: (208,86),(950,86),(950,1310),(208,1310)\n"
     ]
    }
   ],
   "source": [
    "detect_text(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08fafb67-16cc-4d5e-bfb8-24ba44c6ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "Sleeve\n",
      "Dress\n",
      "Collar\n",
      "Electric blue\n",
      "Blazer\n",
      "Magenta\n",
      "Fashion design\n",
      "Fashion accessory\n",
      "Suit\n",
      "Pattern\n"
     ]
    }
   ],
   "source": [
    "detect_labels(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e23c9886-8796-496f-b72c-253869d86abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties:\n",
      "fraction: 0.4453561305999756\n",
      "\tr: 197.0\n",
      "\tg: 195.0\n",
      "\tb: 227.0\n",
      "\ta: \n",
      "fraction: 0.0024501425214111805\n",
      "\tr: 84.0\n",
      "\tg: 84.0\n",
      "\tb: 106.0\n",
      "\ta: \n",
      "fraction: 0.5117948651313782\n",
      "\tr: 244.0\n",
      "\tg: 244.0\n",
      "\tb: 250.0\n",
      "\ta: \n",
      "fraction: 0.014700855128467083\n",
      "\tr: 195.0\n",
      "\tg: 190.0\n",
      "\tb: 226.0\n",
      "\ta: \n",
      "fraction: 0.009914529509842396\n",
      "\tr: 155.0\n",
      "\tg: 154.0\n",
      "\tb: 183.0\n",
      "\ta: \n",
      "fraction: 0.00148148147854954\n",
      "\tr: 123.0\n",
      "\tg: 123.0\n",
      "\tb: 151.0\n",
      "\ta: \n",
      "fraction: 0.007806267589330673\n",
      "\tr: 195.0\n",
      "\tg: 194.0\n",
      "\tb: 208.0\n",
      "\ta: \n",
      "fraction: 0.0051282052882015705\n",
      "\tr: 219.0\n",
      "\tg: 216.0\n",
      "\tb: 241.0\n",
      "\ta: \n",
      "fraction: 0.0002279202308272943\n",
      "\tr: 112.0\n",
      "\tg: 114.0\n",
      "\tb: 127.0\n",
      "\ta: \n",
      "fraction: 0.0003418803389649838\n",
      "\tr: 149.0\n",
      "\tg: 151.0\n",
      "\tb: 164.0\n",
      "\ta: \n"
     ]
    }
   ],
   "source": [
    "detect_properties(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040fe89-092d-47de-b003-c6daa7fa2f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

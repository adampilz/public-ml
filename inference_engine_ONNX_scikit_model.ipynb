{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63e079-d50e-4d2d-90dc-bcb9596356c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdadb32-4d40-46c1-aee2-ff3e3fb0f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# follows tutorial found here\n",
    "# https://cloud.google.com/bigquery/docs/making-predictions-with-sklearn-models-in-onnx-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57112bdd-1200-40a2-9170-49b812db8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other important gifts\n",
    "# https://onnx.ai/sklearn-onnx/api_summary.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acfa45-b8c4-4914-ac8b-b250a9d23e79",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccfadb-4940-4b37-98b7-16b979a2e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xgboost -U -q --user\n",
    "! pip install skl2onnx -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e7f26-727a-4b5a-9b87-9184fcf046f4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "982053da-7f6b-4c0c-b0ef-8edfab89a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = ! gcloud config list --format 'value(core.project)'\n",
    "PROJECT_ID = P[0]\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "# raw source data\n",
    "BUCKET_NAME = f\"bkt-{REGION}-data\"\n",
    "BUCKET_PATH = f\"gs://{BUCKET_NAME}\"\n",
    "USE_CASE = \"bq_inference_engine\"\n",
    "\n",
    "# model\n",
    "MODEL_NAME = \"calibration_model\"\n",
    "\n",
    "# BQ\n",
    "BQ_DATASET = \"ds_uscentral1\"\n",
    "BQ_TABLE = \"calibration_test_set\"\n",
    "BQ_MODEL_NAME = f\"bq_{MODEL_NAME}_pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa25c3a-4c10-4e81-a30c-567f595f7d65",
   "metadata": {},
   "source": [
    "# Train an XGBoost classification model with an scikit-learn calibration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4486a-cc04-4f87-b479-9133a3440d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3238e9d1-e983-4673-81df-e9231b9f56bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score before calibration: 0.017434884531435425\n",
      "Brier score after calibration: 0.020933944128659076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# Load breast cancer dataset\n",
    "data = datasets.load_breast_cancer(as_frame=True)\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "# Initialize and fit XGBoost model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "predicted_probabilities = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print Brier score before calibration\n",
    "print('Brier score before calibration:', brier_score_loss(y_test, predicted_probabilities))\n",
    "\n",
    "# Platt Scaling / Logistic calibration\n",
    "x_predicted_probabilities = predicted_probabilities.reshape(-1, 1)\n",
    "pipe = Pipeline([ ('lr', LogisticRegression() )])\n",
    "pipe.fit(x_predicted_probabilities, y_test)\n",
    "\n",
    "# Calibrated probabilities\n",
    "calibrated_probs = pipe.predict_proba( x_predicted_probabilities )[:, 1]\n",
    "\n",
    "# Print Brier score after calibration\n",
    "print('Brier score after calibration:', brier_score_loss(y_test, calibrated_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65e4dd87-7efc-4a80-a2b0-e39ab3e187df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://calibration_test_set.json [Content-Type=application/json]...\n",
      "/ [1 files][  8.7 KiB/  8.7 KiB]                                                \n",
      "Operation completed over 1 objects/8.7 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Save the predicted probabilities and true labels as a new line delimited json\n",
    "test_set = pd.DataFrame({'predicted_probabilities': predicted_probabilities, 'y_test': y_test})\n",
    "\n",
    "# write out\n",
    "calibration_test_set_name = f\"{BQ_TABLE}.json\"\n",
    "test_set.to_json(calibration_test_set_name, orient='records', lines=True)\n",
    "\n",
    "# save to GCS\n",
    "calibration_test_set_uri = f\"{BUCKET_PATH}/{USE_CASE}/{calibration_test_set_name}\"\n",
    "! gsutil cp {calibration_test_set_name} {calibration_test_set_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1daa9baa-bdb3-4485-995c-95ae4c4dcf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predicted_probabilities\":0.9928037524,\"y_test\":1}\n",
      "{\"predicted_probabilities\":0.0002118868,\"y_test\":0}\n"
     ]
    }
   ],
   "source": [
    "# data to load into BigQuery\n",
    "! head -n 2 calibration_test_set.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd1c511b-bae7-4ef7-a49b-d0b43ca49c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job finished.\n",
      "Loaded 171 rows.\n"
     ]
    }
   ],
   "source": [
    "def load_to_bq(PROJECT_ID, REGION, BQ_DATASET, BQ_TABLE, GCS_URI):\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client(location=REGION, project=PROJECT_ID)\n",
    "\n",
    "    # TODO(developer): Set table_id to the ID of the table to create.\n",
    "    table_id = f\"{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}\"\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        autodetect=True,\n",
    "        source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON, )\n",
    "\n",
    "    load_job = client.load_table_from_uri(\n",
    "        GCS_URI,\n",
    "        table_id,\n",
    "        location=REGION,\n",
    "        job_config=job_config, )\n",
    "\n",
    "    assert load_job.job_type == \"load\"\n",
    "\n",
    "    load_job.result()  # Waits for the job to complete.\n",
    "    print('Job finished.')\n",
    "\n",
    "    assert load_job.state == \"DONE\"\n",
    "    destination_table = client.get_table(table_id)\n",
    "    print('Loaded {} rows.'.format(destination_table.num_rows))\n",
    "    \n",
    "# Load to BQ\n",
    "load_to_bq(PROJECT_ID, REGION, BQ_DATASET, BQ_TABLE, calibration_test_set_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286611fb-988e-402b-aa2c-d0b84aa53838",
   "metadata": {},
   "source": [
    "# Convert the model into ONNX format and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71ca78c7-55a2-4859-91d9-4f2fcdd60ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bcc9052-cfb0-4514-9ae3-81314002d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable zipmap as it is not supported in BigQuery ML.\n",
    "options = {id(pipe): {'zipmap': False}}\n",
    "\n",
    "# Define input features. scikit-learn does not store information about the\n",
    "# training dataset. It is not always possible to retrieve the number of features\n",
    "# or their types. That's why the function needs another argument called initial_types. Example\n",
    "\n",
    "# define initial types\n",
    "initial_types = [('predicted_probabilities', FloatTensorType([None, 1]))]\n",
    "\n",
    "# Convert the model.\n",
    "model_onnx = convert_sklearn(\n",
    "   pipe, MODEL_NAME, initial_types=initial_types, options=options\n",
    "    , target_opset=17 # if not set, uses 18 which is unsupported\n",
    ")\n",
    "\n",
    "# Save the calibration model\n",
    "calibration_model_name = f\"{MODEL_NAME}.onnx\"\n",
    "with open(calibration_model_name, 'wb') as f:\n",
    "    f.write(model_onnx.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce3ee9-2e09-4bfd-8b58-6312cfb8f2ff",
   "metadata": {},
   "source": [
    "# Upload the ONNX model to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48d9a7b7-e30d-4b35-90b8-756f06413293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://calibration_model.onnx [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  493.0 B/  493.0 B]                                                \n",
      "Operation completed over 1 objects/493.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "calibration_model_uri = f\"{BUCKET_PATH}/{USE_CASE}/{calibration_model_name}\"\n",
    "! gsutil cp {calibration_model_name} {calibration_model_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4e619-57c3-4bc4-ba4e-7b1873a7b809",
   "metadata": {},
   "source": [
    "# Import the ONNX model into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7734525e-1a3a-4cbc-ab89-63bf17243c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_engine_model(PROJECT_ID, REGION, BQ_DATASET, BQ_MODEL_NAME, GCS_URI):\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client(location=REGION, project=PROJECT_ID)\n",
    "\n",
    "    # Create Remote Model In BigQuery\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{PROJECT_ID}.{BQ_DATASET}.{BQ_MODEL_NAME}`\n",
    "        OPTIONS (MODEL_TYPE='ONNX', MODEL_PATH='{GCS_URI}')\n",
    "    \"\"\"\n",
    "    job = client.query(query = query)\n",
    "    job.result()\n",
    "    job.state\n",
    "    \n",
    "create_inference_engine_model(PROJECT_ID, REGION, BQ_DATASET, BQ_MODEL_NAME, calibration_model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ae731-5dcd-4a8b-8e06-3fb7a7acb5db",
   "metadata": {},
   "source": [
    "# Make predictions with the imported ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "179f775b-0ece-4efe-84b4-a88400e151f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_inference_calibration_model(PROJECT_ID, REGION, BQ_DATASET, BQ_MODEL_NAME, BQ_TABLE):\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client(location=REGION, project=PROJECT_ID)\n",
    "\n",
    "    # Create Remote Model In BigQuery\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM ML.PREDICT(MODEL {BQ_DATASET}.{BQ_MODEL_NAME},\n",
    "     (\n",
    "      SELECT * FROM {PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}\n",
    "     )\n",
    "    )\n",
    "    \"\"\"\n",
    "    job = client.query(query = query)\n",
    "    df =job.to_dataframe()\n",
    "    return df\n",
    "    \n",
    "df = perform_inference_calibration_model(PROJECT_ID, REGION, BQ_DATASET, BQ_MODEL_NAME, BQ_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88e83084-d54e-4c08-bc40-74866015a551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>y_test</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.9070160984992981, 0.0929839015007019]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.9067691564559937, 0.09323084354400635]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.9069318771362305, 0.09306815266609192]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.9068508148193359, 0.09314921498298645]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.8072217702865601, 0.19277822971343994]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.05622914433479309, 0.9437708854675293]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.056327998638153076, 0.9436720013618469]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.08223989605903625, 0.9177601337432861]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.056580156087875366, 0.9434198141098022]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.05884489417076111, 0.9411550760269165]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                               probabilities  y_test  \\\n",
       "0        0    [0.9070160984992981, 0.0929839015007019]       0   \n",
       "1        0   [0.9067691564559937, 0.09323084354400635]       0   \n",
       "2        0   [0.9069318771362305, 0.09306815266609192]       0   \n",
       "3        0   [0.9068508148193359, 0.09314921498298645]       0   \n",
       "4        0   [0.8072217702865601, 0.19277822971343994]       0   \n",
       "..     ...                                         ...     ...   \n",
       "166      1   [0.05622914433479309, 0.9437708854675293]       1   \n",
       "167      1  [0.056327998638153076, 0.9436720013618469]       1   \n",
       "168      1   [0.08223989605903625, 0.9177601337432861]       1   \n",
       "169      1  [0.056580156087875366, 0.9434198141098022]       1   \n",
       "170      1   [0.05884489417076111, 0.9411550760269165]       1   \n",
       "\n",
       "     predicted_probabilities  \n",
       "0                   0.000212  \n",
       "1                   0.000785  \n",
       "2                   0.000408  \n",
       "3                   0.000596  \n",
       "4                   0.166007  \n",
       "..                       ...  \n",
       "166                 0.999710  \n",
       "167                 0.999345  \n",
       "168                 0.919692  \n",
       "169                 0.998417  \n",
       "170                 0.990251  \n",
       "\n",
       "[171 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
